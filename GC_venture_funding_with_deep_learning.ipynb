{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmEcaJzVURr_"
      },
      "source": [
        "# Venture Funding with Deep Learning\n",
        "\n",
        "You work as a risk management associate at Alphabet Soup, a venture capital firm. Alphabet Soup’s business team receives many funding applications from startups every day. This team has asked you to help them create a model that predicts whether applicants will be successful if funded by Alphabet Soup.\n",
        "\n",
        "The business team has given you a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years. With your knowledge of machine learning and neural networks, you decide to use the features in the provided dataset to create a binary classifier model that will predict whether an applicant will become a successful business. The CSV file contains a variety of information about these businesses, including whether or not they ultimately became successful.\n",
        "\n",
        "## Instructions:\n",
        "\n",
        "The steps for this challenge are broken out into the following sections:\n",
        "\n",
        "* Prepare the data for use on a neural network model.\n",
        "\n",
        "* Compile and evaluate a binary classification model using a neural network.\n",
        "\n",
        "* Optimize the neural network model.\n",
        "\n",
        "### Prepare the Data for Use on a Neural Network Model \n",
        "\n",
        "Using your knowledge of Pandas and scikit-learn’s `StandardScaler()`, preprocess the dataset so that you can use it to compile and evaluate the neural network model later.\n",
        "\n",
        "Open the starter code file, and complete the following data preparation steps:\n",
        "\n",
        "1. Read the `applicants_data.csv` file into a Pandas DataFrame. Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.   \n",
        "\n",
        "2. Drop the “EIN” (Employer Identification Number) and “NAME” columns from the DataFrame, because they are not relevant to the binary classification model.\n",
        " \n",
        "3. Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame.\n",
        "\n",
        "4. Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
        "\n",
        "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. \n",
        "\n",
        "5. Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
        "\n",
        "6. Split the features and target sets into training and testing datasets.\n",
        "\n",
        "7. Use scikit-learn's `StandardScaler` to scale the features data.\n",
        "\n",
        "### Compile and Evaluate a Binary Classification Model Using a Neural Network\n",
        "\n",
        "Use your knowledge of TensorFlow to design a binary classification deep neural network model. This model should use the dataset’s features to predict whether an Alphabet Soup&ndash;funded startup will be successful based on the features in the dataset. Consider the number of inputs before determining the number of layers that your model will contain or the number of neurons on each layer. Then, compile and fit your model. Finally, evaluate your binary classification model to calculate the model’s loss and accuracy. \n",
        " \n",
        "To do so, complete the following steps:\n",
        "\n",
        "1. Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
        "\n",
        "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n",
        "\n",
        "2. Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n",
        "\n",
        "> **Hint** When fitting the model, start with a small number of epochs, such as 20, 50, or 100.\n",
        "\n",
        "3. Evaluate the model using the test data to determine the model’s loss and accuracy.\n",
        "\n",
        "4. Save and export your model to an HDF5 file, and name the file `AlphabetSoup.h5`. \n",
        "\n",
        "### Optimize the Neural Network Model\n",
        "\n",
        "Using your knowledge of TensorFlow and Keras, optimize your model to improve the model's accuracy. Even if you do not successfully achieve a better accuracy, you'll need to demonstrate at least two attempts to optimize the model. You can include these attempts in your existing notebook. Or, you can make copies of the starter notebook in the same folder, rename them, and code each model optimization in a new notebook. \n",
        "\n",
        "> **Note** You will not lose points if your model does not achieve a high accuracy, as long as you make at least two attempts to optimize the model.\n",
        "\n",
        "To do so, complete the following steps:\n",
        "\n",
        "1. Define at least three new deep neural network models (the original plus 2 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
        "\n",
        "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
        ">\n",
        "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
        ">\n",
        "> * Add more neurons (nodes) to a hidden layer.\n",
        ">\n",
        "> * Add more hidden layers.\n",
        ">\n",
        "> * Use different activation functions for the hidden layers.\n",
        ">\n",
        "> * Add to or reduce the number of epochs in the training regimen.\n",
        "\n",
        "2. After finishing your models, display the accuracy scores achieved by each model, and compare the results.\n",
        "\n",
        "3. Save each of your models as an HDF5 file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6XiL4BeyURsD"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzvfMq--URsD"
      },
      "source": [
        "---\n",
        "\n",
        "## Prepare the data to be used on a neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJWhWy1zURsE"
      },
      "source": [
        "### Step 1: Read the `applicants_data.csv` file into a Pandas DataFrame. Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5GsFRRuGU9r-",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "dbe0fec9-4cc1-419c-9011-1922e6a66f9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-958b0240-afdd-46db-9663-6300621bf805\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-958b0240-afdd-46db-9663-6300621bf805\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving applicants_data.csv to applicants_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Upload credit_card_transactions.csv to Colab\n",
        "from google.colab import files\n",
        "\n",
        "csv_file = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gSTFDSzYURsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bf690b85-9f97-4105-d006-e4b65008e0c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f638b64-863a-4a26-acdd-3f37ff4450b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f638b64-863a-4a26-acdd-3f37ff4450b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f638b64-863a-4a26-acdd-3f37ff4450b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f638b64-863a-4a26-acdd-3f37ff4450b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame\n",
        "applicant_data_df = pd.read_csv(\"applicants_data.csv\")\n",
        "\n",
        "# Review the DataFrame\n",
        "applicant_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C-WB0yc4URsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bea229e-ac47-4de1-cddd-86e5e75d3dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EIN',\n",
              " 'NAME',\n",
              " 'APPLICATION_TYPE',\n",
              " 'AFFILIATION',\n",
              " 'CLASSIFICATION',\n",
              " 'USE_CASE',\n",
              " 'ORGANIZATION',\n",
              " 'STATUS',\n",
              " 'INCOME_AMT',\n",
              " 'SPECIAL_CONSIDERATIONS',\n",
              " 'ASK_AMT',\n",
              " 'IS_SUCCESSFUL']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Review the data types associated with the columns\n",
        "list(applicant_data_df.dtypes.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCwg3ahTURsE"
      },
      "source": [
        "### Step 2: Drop the “EIN” (Employer Identification Number) and “NAME” columns from the DataFrame, because they are not relevant to the binary classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dj7yoYaAURsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "6a0baf8e-7dfb-4b00-a247-7ec09db436fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0                  T10       Independent          C1000    ProductDev   \n",
              "1                   T3       Independent          C2000  Preservation   \n",
              "2                   T5  CompanySponsored          C3000    ProductDev   \n",
              "3                   T3  CompanySponsored          C2000  Preservation   \n",
              "4                   T3       Independent          C1000     Heathcare   \n",
              "...                ...               ...            ...           ...   \n",
              "34294               T4       Independent          C1000    ProductDev   \n",
              "34295               T4  CompanySponsored          C3000    ProductDev   \n",
              "34296               T3  CompanySponsored          C2000  Preservation   \n",
              "34297               T5       Independent          C3000    ProductDev   \n",
              "34298               T3       Independent          C1000  Preservation   \n",
              "\n",
              "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
              "0       Association       1              0                      N      5000   \n",
              "1      Co-operative       1         1-9999                      N    108590   \n",
              "2       Association       1              0                      N      5000   \n",
              "3             Trust       1    10000-24999                      N      6692   \n",
              "4             Trust       1  100000-499999                      N    142590   \n",
              "...             ...     ...            ...                    ...       ...   \n",
              "34294   Association       1              0                      N      5000   \n",
              "34295   Association       1              0                      N      5000   \n",
              "34296   Association       1              0                      N      5000   \n",
              "34297   Association       1              0                      N      5000   \n",
              "34298  Co-operative       1          1M-5M                      N  36500179   \n",
              "\n",
              "       IS_SUCCESSFUL  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "34294              0  \n",
              "34295              0  \n",
              "34296              0  \n",
              "34297              1  \n",
              "34298              0  \n",
              "\n",
              "[34299 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0396ac5-1d98-4cbd-9412-871af3b2543e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>T4</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>T4</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>T5</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1M-5M</td>\n",
              "      <td>N</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0396ac5-1d98-4cbd-9412-871af3b2543e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0396ac5-1d98-4cbd-9412-871af3b2543e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0396ac5-1d98-4cbd-9412-871af3b2543e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Drop the 'EIN' and 'NAME' columns from the DataFrame\n",
        "applicant_data_df = applicant_data_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "\n",
        "# Review the DataFrame\n",
        "applicant_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFF35NwZURsF"
      },
      "source": [
        "### Step 3: Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aHv_okM7URsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3488959a-8c60-4720-c1a0-166282043b47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['APPLICATION_TYPE',\n",
              " 'AFFILIATION',\n",
              " 'CLASSIFICATION',\n",
              " 'USE_CASE',\n",
              " 'ORGANIZATION',\n",
              " 'INCOME_AMT',\n",
              " 'SPECIAL_CONSIDERATIONS']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Create a list of categorical variables \n",
        "categorical_variables = list(applicant_data_df.dtypes[applicant_data_df.dtypes == \"object\"].index)\n",
        "\n",
        "\n",
        "# Display the categorical variables list\n",
        "categorical_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IizC83_xURsF"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fLUlCo48URsF"
      },
      "outputs": [],
      "source": [
        "# Encode the categorcal variables using OneHotEncoder\n",
        "encoded_data = enc.fit_transform(applicant_data_df[categorical_variables])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bj-Hc08qURsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "d7d70da5-c104-482f-ff22-4541003aec26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
              "0                       1.0                   0.0                   0.0   \n",
              "1                       0.0                   0.0                   0.0   \n",
              "2                       0.0                   0.0                   0.0   \n",
              "3                       0.0                   0.0                   0.0   \n",
              "4                       0.0                   0.0                   0.0   \n",
              "...                     ...                   ...                   ...   \n",
              "34294                   0.0                   0.0                   0.0   \n",
              "34295                   0.0                   0.0                   0.0   \n",
              "34296                   0.0                   0.0                   0.0   \n",
              "34297                   0.0                   0.0                   0.0   \n",
              "34298                   0.0                   0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
              "0                       0.0                   0.0                   0.0   \n",
              "1                       0.0                   0.0                   0.0   \n",
              "2                       0.0                   0.0                   0.0   \n",
              "3                       0.0                   0.0                   0.0   \n",
              "4                       0.0                   0.0                   0.0   \n",
              "...                     ...                   ...                   ...   \n",
              "34294                   0.0                   0.0                   0.0   \n",
              "34295                   0.0                   0.0                   0.0   \n",
              "34296                   0.0                   0.0                   0.0   \n",
              "34297                   0.0                   0.0                   0.0   \n",
              "34298                   0.0                   0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
              "0                       0.0                  0.0                   0.0   \n",
              "1                       0.0                  0.0                   0.0   \n",
              "2                       0.0                  0.0                   0.0   \n",
              "3                       0.0                  0.0                   0.0   \n",
              "4                       0.0                  0.0                   0.0   \n",
              "...                     ...                  ...                   ...   \n",
              "34294                   0.0                  0.0                   0.0   \n",
              "34295                   0.0                  0.0                   0.0   \n",
              "34296                   0.0                  0.0                   0.0   \n",
              "34297                   0.0                  0.0                   0.0   \n",
              "34298                   0.0                  0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T29  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
              "0                       0.0  ...                0.0                     0.0   \n",
              "1                       0.0  ...                1.0                     0.0   \n",
              "2                       0.0  ...                0.0                     0.0   \n",
              "3                       0.0  ...                0.0                     1.0   \n",
              "4                       0.0  ...                0.0                     0.0   \n",
              "...                     ...  ...                ...                     ...   \n",
              "34294                   0.0  ...                0.0                     0.0   \n",
              "34295                   0.0  ...                0.0                     0.0   \n",
              "34296                   0.0  ...                0.0                     0.0   \n",
              "34297                   0.0  ...                0.0                     0.0   \n",
              "34298                   0.0  ...                0.0                     0.0   \n",
              "\n",
              "       INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
              "0                           0.0                 0.0               0.0   \n",
              "1                           0.0                 0.0               0.0   \n",
              "2                           0.0                 0.0               0.0   \n",
              "3                           0.0                 0.0               0.0   \n",
              "4                           1.0                 0.0               0.0   \n",
              "...                         ...                 ...               ...   \n",
              "34294                       0.0                 0.0               0.0   \n",
              "34295                       0.0                 0.0               0.0   \n",
              "34296                       0.0                 0.0               0.0   \n",
              "34297                       0.0                 0.0               0.0   \n",
              "34298                       0.0                 0.0               1.0   \n",
              "\n",
              "       INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
              "0                         0.0              0.0                0.0   \n",
              "1                         0.0              0.0                0.0   \n",
              "2                         0.0              0.0                0.0   \n",
              "3                         0.0              0.0                0.0   \n",
              "4                         0.0              0.0                0.0   \n",
              "...                       ...              ...                ...   \n",
              "34294                     0.0              0.0                0.0   \n",
              "34295                     0.0              0.0                0.0   \n",
              "34296                     0.0              0.0                0.0   \n",
              "34297                     0.0              0.0                0.0   \n",
              "34298                     0.0              0.0                0.0   \n",
              "\n",
              "       SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                           1.0                       0.0  \n",
              "1                           1.0                       0.0  \n",
              "2                           1.0                       0.0  \n",
              "3                           1.0                       0.0  \n",
              "4                           1.0                       0.0  \n",
              "...                         ...                       ...  \n",
              "34294                       1.0                       0.0  \n",
              "34295                       1.0                       0.0  \n",
              "34296                       1.0                       0.0  \n",
              "34297                       1.0                       0.0  \n",
              "34298                       1.0                       0.0  \n",
              "\n",
              "[34299 rows x 114 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6083f5df-655f-428c-8a01-559dc27d9140\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T12</th>\n",
              "      <th>APPLICATION_TYPE_T13</th>\n",
              "      <th>APPLICATION_TYPE_T14</th>\n",
              "      <th>APPLICATION_TYPE_T15</th>\n",
              "      <th>APPLICATION_TYPE_T17</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T2</th>\n",
              "      <th>APPLICATION_TYPE_T25</th>\n",
              "      <th>APPLICATION_TYPE_T29</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows × 114 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6083f5df-655f-428c-8a01-559dc27d9140')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6083f5df-655f-428c-8a01-559dc27d9140 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6083f5df-655f-428c-8a01-559dc27d9140');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Create a DataFrame with the encoded variables\n",
        "encoded_df = pd.DataFrame(\n",
        "    encoded_data,\n",
        "    columns = enc.get_feature_names(categorical_variables)\n",
        ")\n",
        "\n",
        "# Review the DataFrame\n",
        "encoded_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Bd0AQTURsF"
      },
      "source": [
        "### Step 4: Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
        "\n",
        "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r43_PQpFURsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "0f3090e1-98c1-41e0-c6bd-1a112dbe521a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
              "0                       1.0                   0.0                   0.0   \n",
              "1                       0.0                   0.0                   0.0   \n",
              "2                       0.0                   0.0                   0.0   \n",
              "3                       0.0                   0.0                   0.0   \n",
              "4                       0.0                   0.0                   0.0   \n",
              "...                     ...                   ...                   ...   \n",
              "34294                   0.0                   0.0                   0.0   \n",
              "34295                   0.0                   0.0                   0.0   \n",
              "34296                   0.0                   0.0                   0.0   \n",
              "34297                   0.0                   0.0                   0.0   \n",
              "34298                   0.0                   0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
              "0                       0.0                   0.0                   0.0   \n",
              "1                       0.0                   0.0                   0.0   \n",
              "2                       0.0                   0.0                   0.0   \n",
              "3                       0.0                   0.0                   0.0   \n",
              "4                       0.0                   0.0                   0.0   \n",
              "...                     ...                   ...                   ...   \n",
              "34294                   0.0                   0.0                   0.0   \n",
              "34295                   0.0                   0.0                   0.0   \n",
              "34296                   0.0                   0.0                   0.0   \n",
              "34297                   0.0                   0.0                   0.0   \n",
              "34298                   0.0                   0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
              "0                       0.0                  0.0                   0.0   \n",
              "1                       0.0                  0.0                   0.0   \n",
              "2                       0.0                  0.0                   0.0   \n",
              "3                       0.0                  0.0                   0.0   \n",
              "4                       0.0                  0.0                   0.0   \n",
              "...                     ...                  ...                   ...   \n",
              "34294                   0.0                  0.0                   0.0   \n",
              "34295                   0.0                  0.0                   0.0   \n",
              "34296                   0.0                  0.0                   0.0   \n",
              "34297                   0.0                  0.0                   0.0   \n",
              "34298                   0.0                  0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T29  ...  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
              "0                       0.0  ...                 0.0               0.0   \n",
              "1                       0.0  ...                 0.0               0.0   \n",
              "2                       0.0  ...                 0.0               0.0   \n",
              "3                       0.0  ...                 0.0               0.0   \n",
              "4                       0.0  ...                 0.0               0.0   \n",
              "...                     ...  ...                 ...               ...   \n",
              "34294                   0.0  ...                 0.0               0.0   \n",
              "34295                   0.0  ...                 0.0               0.0   \n",
              "34296                   0.0  ...                 0.0               0.0   \n",
              "34297                   0.0  ...                 0.0               0.0   \n",
              "34298                   0.0  ...                 0.0               1.0   \n",
              "\n",
              "       INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
              "0                         0.0              0.0                0.0   \n",
              "1                         0.0              0.0                0.0   \n",
              "2                         0.0              0.0                0.0   \n",
              "3                         0.0              0.0                0.0   \n",
              "4                         0.0              0.0                0.0   \n",
              "...                       ...              ...                ...   \n",
              "34294                     0.0              0.0                0.0   \n",
              "34295                     0.0              0.0                0.0   \n",
              "34296                     0.0              0.0                0.0   \n",
              "34297                     0.0              0.0                0.0   \n",
              "34298                     0.0              0.0                0.0   \n",
              "\n",
              "       SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  STATUS   ASK_AMT  \\\n",
              "0                           1.0                       0.0       1      5000   \n",
              "1                           1.0                       0.0       1    108590   \n",
              "2                           1.0                       0.0       1      5000   \n",
              "3                           1.0                       0.0       1      6692   \n",
              "4                           1.0                       0.0       1    142590   \n",
              "...                         ...                       ...     ...       ...   \n",
              "34294                       1.0                       0.0       1      5000   \n",
              "34295                       1.0                       0.0       1      5000   \n",
              "34296                       1.0                       0.0       1      5000   \n",
              "34297                       1.0                       0.0       1      5000   \n",
              "34298                       1.0                       0.0       1  36500179   \n",
              "\n",
              "       IS_SUCCESSFUL  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "34294              0  \n",
              "34295              0  \n",
              "34296              0  \n",
              "34297              1  \n",
              "34298              0  \n",
              "\n",
              "[34299 rows x 117 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc013728-21b7-4d04-ac8e-f5b716238f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T12</th>\n",
              "      <th>APPLICATION_TYPE_T13</th>\n",
              "      <th>APPLICATION_TYPE_T14</th>\n",
              "      <th>APPLICATION_TYPE_T15</th>\n",
              "      <th>APPLICATION_TYPE_T17</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T2</th>\n",
              "      <th>APPLICATION_TYPE_T25</th>\n",
              "      <th>APPLICATION_TYPE_T29</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows × 117 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc013728-21b7-4d04-ac8e-f5b716238f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc013728-21b7-4d04-ac8e-f5b716238f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc013728-21b7-4d04-ac8e-f5b716238f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
        "numerical_variables_df = applicant_data_df.drop(columns=categorical_variables)\n",
        "encoded_df = pd.concat([encoded_df, numerical_variables_df], axis=1)\n",
        "\n",
        "# Review the Dataframe\n",
        "encoded_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJHzn3uyURsG"
      },
      "source": [
        "### Step 5: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XpmWKy35URsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02dd814-83f0-41af-a593-2b4ea3aab913"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        0\n",
              "3        1\n",
              "4        1\n",
              "        ..\n",
              "34294    0\n",
              "34295    0\n",
              "34296    0\n",
              "34297    1\n",
              "34298    0\n",
              "Name: IS_SUCCESSFUL, Length: 34299, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Define the target set y using the IS_SUCCESSFUL column\n",
        "y = encoded_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Display a sample of y\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SzVEfRlaURsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "2cef2a21-f47a-4e35-de88-121e5e5a427d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
              "0                       1.0                   0.0                   0.0   \n",
              "1                       0.0                   0.0                   0.0   \n",
              "2                       0.0                   0.0                   0.0   \n",
              "3                       0.0                   0.0                   0.0   \n",
              "4                       0.0                   0.0                   0.0   \n",
              "...                     ...                   ...                   ...   \n",
              "34294                   0.0                   0.0                   0.0   \n",
              "34295                   0.0                   0.0                   0.0   \n",
              "34296                   0.0                   0.0                   0.0   \n",
              "34297                   0.0                   0.0                   0.0   \n",
              "34298                   0.0                   0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
              "0                       0.0                   0.0                   0.0   \n",
              "1                       0.0                   0.0                   0.0   \n",
              "2                       0.0                   0.0                   0.0   \n",
              "3                       0.0                   0.0                   0.0   \n",
              "4                       0.0                   0.0                   0.0   \n",
              "...                     ...                   ...                   ...   \n",
              "34294                   0.0                   0.0                   0.0   \n",
              "34295                   0.0                   0.0                   0.0   \n",
              "34296                   0.0                   0.0                   0.0   \n",
              "34297                   0.0                   0.0                   0.0   \n",
              "34298                   0.0                   0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
              "0                       0.0                  0.0                   0.0   \n",
              "1                       0.0                  0.0                   0.0   \n",
              "2                       0.0                  0.0                   0.0   \n",
              "3                       0.0                  0.0                   0.0   \n",
              "4                       0.0                  0.0                   0.0   \n",
              "...                     ...                  ...                   ...   \n",
              "34294                   0.0                  0.0                   0.0   \n",
              "34295                   0.0                  0.0                   0.0   \n",
              "34296                   0.0                  0.0                   0.0   \n",
              "34297                   0.0                  0.0                   0.0   \n",
              "34298                   0.0                  0.0                   0.0   \n",
              "\n",
              "       APPLICATION_TYPE_T29  ...  INCOME_AMT_100000-499999  \\\n",
              "0                       0.0  ...                       0.0   \n",
              "1                       0.0  ...                       0.0   \n",
              "2                       0.0  ...                       0.0   \n",
              "3                       0.0  ...                       0.0   \n",
              "4                       0.0  ...                       1.0   \n",
              "...                     ...  ...                       ...   \n",
              "34294                   0.0  ...                       0.0   \n",
              "34295                   0.0  ...                       0.0   \n",
              "34296                   0.0  ...                       0.0   \n",
              "34297                   0.0  ...                       0.0   \n",
              "34298                   0.0  ...                       0.0   \n",
              "\n",
              "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                     0.0               0.0                     0.0   \n",
              "1                     0.0               0.0                     0.0   \n",
              "2                     0.0               0.0                     0.0   \n",
              "3                     0.0               0.0                     0.0   \n",
              "4                     0.0               0.0                     0.0   \n",
              "...                   ...               ...                     ...   \n",
              "34294                 0.0               0.0                     0.0   \n",
              "34295                 0.0               0.0                     0.0   \n",
              "34296                 0.0               0.0                     0.0   \n",
              "34297                 0.0               0.0                     0.0   \n",
              "34298                 0.0               1.0                     0.0   \n",
              "\n",
              "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0                  0.0                0.0                       1.0   \n",
              "1                  0.0                0.0                       1.0   \n",
              "2                  0.0                0.0                       1.0   \n",
              "3                  0.0                0.0                       1.0   \n",
              "4                  0.0                0.0                       1.0   \n",
              "...                ...                ...                       ...   \n",
              "34294              0.0                0.0                       1.0   \n",
              "34295              0.0                0.0                       1.0   \n",
              "34296              0.0                0.0                       1.0   \n",
              "34297              0.0                0.0                       1.0   \n",
              "34298              0.0                0.0                       1.0   \n",
              "\n",
              "       SPECIAL_CONSIDERATIONS_Y  STATUS   ASK_AMT  \n",
              "0                           0.0       1      5000  \n",
              "1                           0.0       1    108590  \n",
              "2                           0.0       1      5000  \n",
              "3                           0.0       1      6692  \n",
              "4                           0.0       1    142590  \n",
              "...                         ...     ...       ...  \n",
              "34294                       0.0       1      5000  \n",
              "34295                       0.0       1      5000  \n",
              "34296                       0.0       1      5000  \n",
              "34297                       0.0       1      5000  \n",
              "34298                       0.0       1  36500179  \n",
              "\n",
              "[34299 rows x 116 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-daa99b28-7897-46c8-b7c4-84a27ac84f58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T12</th>\n",
              "      <th>APPLICATION_TYPE_T13</th>\n",
              "      <th>APPLICATION_TYPE_T14</th>\n",
              "      <th>APPLICATION_TYPE_T15</th>\n",
              "      <th>APPLICATION_TYPE_T17</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T2</th>\n",
              "      <th>APPLICATION_TYPE_T25</th>\n",
              "      <th>APPLICATION_TYPE_T29</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>36500179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows × 116 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daa99b28-7897-46c8-b7c4-84a27ac84f58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-daa99b28-7897-46c8-b7c4-84a27ac84f58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-daa99b28-7897-46c8-b7c4-84a27ac84f58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Define features set X by selecting all columns but IS_SUCCESSFUL\n",
        "X = encoded_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
        "\n",
        "# Review the features DataFrame\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgb0PFDKURsG"
      },
      "source": [
        "### Step 6: Split the features and target sets into training and testing datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M_vGfjV4URsG"
      },
      "outputs": [],
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "# Assign the function a random_state equal to 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDcNY8TGURsG"
      },
      "source": [
        "### Step 7: Use scikit-learn's `StandardScaler` to scale the features data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MWOH8vl-URsG"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features training dataset\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "\n",
        "# Fit the scaler to the features training dataset\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvE_rJAAURsH"
      },
      "source": [
        "---\n",
        "\n",
        "## Compile and Evaluate a Binary Classification Model Using a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLD8vtTqURsH"
      },
      "source": [
        "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
        "\n",
        "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "K1Vgwz04URsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b09887-6561-4b00-b575-f79cde8c4a92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Define the the number of inputs (features) to the model\n",
        "number_input_features = len(X_train.iloc[0])\n",
        "\n",
        "# Review the number of features\n",
        "number_input_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0mcgkl8SURsH"
      },
      "outputs": [],
      "source": [
        "# Define the number of neurons in the output layer\n",
        "number_output_neurons = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "i0Q3iY3wURsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d5cbd3-c83d-45c6-9e4d-6b9a0f72b109"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Define the number of hidden nodes for the first hidden layer\n",
        "hidden_nodes_layer1 =  (number_input_features + 1) // 2\n",
        "\n",
        "# Review the number hidden nodes in the first layer\n",
        "hidden_nodes_layer1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ux_lAsrvURsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3150869-aca5-46fd-d641-59fd350aca48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Define the number of hidden nodes for the second hidden layer\n",
        "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
        "\n",
        "# Review the number hidden nodes in the second layer\n",
        "hidden_nodes_layer2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1kq9QWhLURsH"
      },
      "outputs": [],
      "source": [
        "# Create the Sequential model instance\n",
        "nn = Sequential()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NcVrWCD_URsI"
      },
      "outputs": [],
      "source": [
        "# Add the first hidden layer\n",
        "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\", input_dim=number_input_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ugxr6lisURsI"
      },
      "outputs": [],
      "source": [
        "# Add the second hidden layer\n",
        "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QxcGEyNoURsI"
      },
      "outputs": [],
      "source": [
        "# Add the output layer to the model specifying the number of output neurons and activation function\n",
        "nn.add(Dense(units=number_output_neurons, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1L2ZVcXgURsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dcc5de-0517-4869-cb94-169772588e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 58)                6786      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 29)                1711      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 30        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,527\n",
            "Trainable params: 8,527\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Display the Sequential model summary\n",
        "nn.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoKsvI3URsI"
      },
      "source": [
        "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PR8r_cL1URsI"
      },
      "outputs": [],
      "source": [
        "# Compile the Sequential model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5_z-FPHJURsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797c4225-4e3f-4ef9-dd31-36ff45d458af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5737 - accuracy: 0.7205\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7296\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7303\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7331\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7341\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7325\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7326\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7331\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7347\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7349\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7343\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7358\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7360\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7356\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7357\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7364\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7376\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7372\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.7379\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7371\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7379\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7393\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7384\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7370\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7378\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7371\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7385\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7377\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7387\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7385\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7383\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7391\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7390\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7390\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7392\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7401\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7395\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7399\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7395\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7400\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7404\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7398\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7407\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7392\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7390\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7390\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7406\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7399\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7404\n"
          ]
        }
      ],
      "source": [
        "# Fit the model using 50 epochs and the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIbFSQ-FURsI"
      },
      "source": [
        "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rWaHGdGrURsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f8ba19-4b5b-425f-8ef4-b29ca2432574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5530 - accuracy: 0.7294 - 395ms/epoch - 1ms/step\n",
            "Loss: 0.5530143976211548, Accuracy: 0.7294460535049438\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppT2iIP5URsJ"
      },
      "source": [
        "### Step 4: Save and export your model to an HDF5 file, and name the file `AlphabetSoup.h5`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iOuA28RQURsJ"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = \"Resources/AlphabetSoup.h5\"\n",
        "\n",
        "# Export your model to a HDF5 file\n",
        "nn.save(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlN5E4WfURsJ"
      },
      "source": [
        "---\n",
        "\n",
        "## Optimize the neural network model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q7pN2XKURsJ"
      },
      "source": [
        "### Step 1: Define at least three new deep neural network models (resulting in the original plus 3 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
        "\n",
        "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
        ">\n",
        "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
        ">\n",
        "> * Add more neurons (nodes) to a hidden layer.\n",
        ">\n",
        "> * Add more hidden layers.\n",
        ">\n",
        "> * Use different activation functions for the hidden layers.\n",
        ">\n",
        "> * Add to or reduce the number of epochs in the training regimen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slhZ-iS1URsJ"
      },
      "source": [
        "### Alternative Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zqbrMOgCURsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd59238b-dd9e-43b0-d24e-87d55b311c40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Define the the number of inputs (features) to the model\n",
        "number_input_features = len(X_train.iloc[0])\n",
        "\n",
        "# Review the number of features\n",
        "number_input_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "U3rrh76sURsJ"
      },
      "outputs": [],
      "source": [
        "# Define the number of neurons in the output layer\n",
        "number_output_neurons_A1 = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lMOrWGBKURsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a4c387-2945-4dd9-d131-12ad0352177f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Define the number of hidden nodes for the first hidden layer\n",
        "hidden_nodes_layer1_A1 = (number_input_features + 1) // 2\n",
        "\n",
        "# Review the number of hidden nodes in the first layer\n",
        "hidden_nodes_layer1_A1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "efNsx7TfURsK"
      },
      "outputs": [],
      "source": [
        "# Create the Sequential model instance\n",
        "nn_A1 = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0uMhdXQWURsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b1e08c-34e3-4115-f31e-57d581a95ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 58)                6786      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 59        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,845\n",
            "Trainable params: 6,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# First hidden layer\n",
        "nn_A1.add(Dense(units=hidden_nodes_layer1_A1, activation=\"relu\", input_dim=number_input_features))\n",
        "\n",
        "# Output layer\n",
        "nn_A1.add(Dense(units=number_output_neurons_A1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_A1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2gDpRhG7URsK"
      },
      "outputs": [],
      "source": [
        "# Compile the Sequential model\n",
        "nn_A1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "zE4UD4NyURsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d185ad3-8b77-4938-b658-0b0fff86cd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5812 - accuracy: 0.7179\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7283\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.7292\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5511 - accuracy: 0.7306\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7307\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7320\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7315\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7311\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7322\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7322\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7318\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7327\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7321\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7329\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7345\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7342\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7337\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7334\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7341\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7347\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7344\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7344\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7349\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7338\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7350\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7358\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7348\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7345\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7373\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7365\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7364\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7367\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7363\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7374\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7362\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7376\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7364\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7365\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7371\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7363\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7360\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7372\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7373\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7371\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7364\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7359\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7370\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7370\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7379\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "# Fit the model using 50 epochs and the training data\n",
        "fit_model_A1 = nn_A1.fit(X_train_scaled, y_train, epochs=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMZAmHrlURsK"
      },
      "source": [
        "#### Alternative Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Mw0cxkvOURsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66062bd-cc19-4e0b-87cb-cf3ebca62754"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Define the the number of inputs (features) to the model\n",
        "number_input_features = len(X_train.iloc[0])\n",
        "\n",
        "# Review the number of features\n",
        "number_input_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qnLSrAKJURsK"
      },
      "outputs": [],
      "source": [
        "# Define the number of neurons in the output layer\n",
        "number_output_neurons_A2 = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "myK4iGVBURsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e5e20c-80f5-44f0-ef1c-c645a4546b46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Define the number of hidden nodes for the first hidden layer\n",
        "hidden_nodes_layer1_A2 = (hidden_nodes_layer1 + 58) // 2\n",
        "\n",
        "# Review the number of hidden nodes in the first layer\n",
        "hidden_nodes_layer1_A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "lB6J98OSURsL"
      },
      "outputs": [],
      "source": [
        "# Create the Sequential model instance\n",
        "nn_A2 = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "EX5HLuh9URsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2eb4f4a-a9d3-41bc-fd57-b70fdced800e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 58)                6786      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 116)               6844      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 117       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,747\n",
            "Trainable params: 13,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# First hidden layer\n",
        "nn_A2.add(Dense(units=hidden_nodes_layer1_A2, activation=\"relu\", input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn_A2.add(Dense(units=hidden_nodes_layer1_A2 * 2, activation=\"leaky_relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn_A2.add(Dense(units=number_output_neurons_A2, activation=\"sigmoid\"))\n",
        "# Check the structure of the model\n",
        "nn_A2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JrI6zrIRURsL"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn_A2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "8M3fXVn_URsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56baadb-b086-4148-f544-02ee838f79c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5804 - accuracy: 0.7188\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5564 - accuracy: 0.7290\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7296\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7310\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7319\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7332\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7348\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7340\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7345\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7346\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7346\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7362\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7350\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7358\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7357\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7365\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7365\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7373\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7371\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7364\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7367\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7381\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7378\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7378\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7382\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7385\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7386\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7383\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7378\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7383\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7376\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7393\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7391\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7388\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7397\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7403\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7392\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7396\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7395\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7388\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7393\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7395\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7400\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7402\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7386\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7409\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7399\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7399\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7403\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7403\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7402\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7402\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7388\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7397\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7405\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7404\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7413\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7407\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7409\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7402\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7408\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7406\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7407\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7412\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7412\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7406\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7421\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7417\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7407\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7409\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7411\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7405\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7415\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7412\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7406\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7411\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7414\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7404\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7422\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7412\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7412\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7413\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7407\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7412\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7412\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7422\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7409\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7424\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7424\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7416\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7414\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7416\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7421\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7426\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7409\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7420\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7414\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7424\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7411\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7420\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbf397f37d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Fit the model\n",
        "nn_A2.fit(X_train_scaled, y_train, batch_size = 32 ,epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_curves = pd.DataFrame(nn_A2.history.history)\n",
        "lr_curves[\"accuracy\"].plot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9-fuLVBhrlKJ",
        "outputId": "5df04960-4d87-4655-d8bd-4d026c9c84a2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf3958f110>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_curves[\"loss\"].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ljrwV6V5sJXT",
        "outputId": "1ce4d3b5-2b78-4dc5-b75f-29c7e22f6e90"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf394c5e90>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkA48Z4hURsL"
      },
      "source": [
        "### Step 2: After finishing your models, display the accuracy scores achieved by each model, and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "RXhF6K8SURsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2350e2f3-58e6-4cfc-ae42-aec4dbd8ef37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Results\n",
            "268/268 - 0s - loss: 0.5530 - accuracy: 0.7294 - 292ms/epoch - 1ms/step\n",
            "Loss: 0.5530143976211548, Accuracy: 0.7294460535049438\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Model Results\")\n",
        "\n",
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "W52oclvkURsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa3c373-fa8a-4869-d83c-aa67c94f80e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternative Model 1 Results\n",
            "268/268 - 0s - loss: 0.5595 - accuracy: 0.7300 - 373ms/epoch - 1ms/step\n",
            "Loss: 0.5594684481620789, Accuracy: 0.7300291657447815\n"
          ]
        }
      ],
      "source": [
        "print(\"Alternative Model 1 Results\")\n",
        "\n",
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "model_loss, model_accuracy = nn_A1.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4yPtU8_nURsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378bd62d-9978-4c30-cb67-a75f46487cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternative Model 2 Results\n",
            "268/268 - 0s - loss: 0.5652 - accuracy: 0.7305 - 396ms/epoch - 1ms/step\n",
            "Loss: 0.5651640892028809, Accuracy: 0.7304956316947937\n"
          ]
        }
      ],
      "source": [
        "print(\"Alternative Model 2 Results\")\n",
        "\n",
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "model_loss, model_accuracy = nn_A2.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ3b2y7OURsM"
      },
      "source": [
        "### Step 3: Save each of your alternative models as an HDF5 file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "a1tXiNBZURsM"
      },
      "outputs": [],
      "source": [
        "# Set the file path for the first alternative model\n",
        "file_path_A1 = \"Resources/AlphabetSoup_A1.h5\"\n",
        "\n",
        "# Export your model to a HDF5 file\n",
        "nn_A1.save(file_path_A1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "W9KTZW35URsM"
      },
      "outputs": [],
      "source": [
        "# Set the file path for the second alternative model\n",
        "file_path_A2 = \"Resources/AlphabetSoup_A2.h5\"\n",
        "\n",
        "# Export your model to a HDF5 file\n",
        "nn_A2.save(file_path_A2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "IiQ2lyQuURsM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GC_venture_funding_with_deep_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}